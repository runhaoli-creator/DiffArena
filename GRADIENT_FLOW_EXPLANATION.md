# æ¢¯åº¦æµéªŒè¯è¯´æ˜

## ğŸ“Š æ¢¯åº¦æµè·¯å¾„å›¾

```
æµ‹è¯•è„šæœ¬ä¸­çš„æ¢¯åº¦æµè·¯å¾„ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. èµ·ç‚¹ï¼šLoss è®¡ç®—                                           â”‚
â”‚    loss = F.mse_loss(output, target)                         â”‚
â”‚    â†“                                                          â”‚
â”‚    è¿™æ˜¯ä¸€ä¸ªæ ‡é‡ï¼ˆå•ä¸ªæ•°å€¼ï¼‰ï¼Œéœ€è¦åå‘ä¼ æ’­                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ backward()
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ä¸­é—´å±‚ï¼šSampler çš„è¾“å‡º                                     â”‚
â”‚    output = sampler._forward_impl(...)                       â”‚
â”‚    â†“                                                          â”‚
â”‚    output æ˜¯ç»è¿‡æ•´ä¸ªé‡‡æ ·è¿‡ç¨‹åçš„æœ€ç»ˆç»“æœ                      â”‚
â”‚    output.requires_grad = True âœ…                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. é‡‡æ ·è¿‡ç¨‹ï¼šå¤šæ­¥è¿­ä»£ï¼ˆ4 æ­¥ï¼‰                                â”‚
â”‚    for step in range(num_steps):                             â”‚
â”‚        x_t = denoiser(x_t, sigma_t)  # æ¯ä¸€æ­¥éƒ½è°ƒç”¨ denoiserâ”‚
â”‚        if learnable_step_noise:                              â”‚
â”‚            x_t += noise_scale * step_noise[i]  # ä» z0 æ´¾ç”Ÿ  â”‚
â”‚    â†“                                                          â”‚
â”‚    æ¯ä¸€æ­¥çš„ denoiser å’Œå™ªå£°æ³¨å…¥éƒ½ä¿æŒæ¢¯åº¦è¿æ¥                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. åˆå§‹çŠ¶æ€ï¼šx_T = sigma_max * z0                            â”‚
â”‚    (åœ¨ res_sampler.py ç¬¬ 220 è¡Œ)                             â”‚
â”‚    â†“                                                          â”‚
â”‚    z0 = torch.randn_like(...)                                â”‚
â”‚    z0.requires_grad_(True) âœ…                                â”‚
â”‚    input_xT = sigma_max * z0                                 â”‚
â”‚    â†“                                                          â”‚
â”‚    z0 æ˜¯**åˆå§‹å™ªå£°**ï¼Œè¿™æ˜¯æˆ‘ä»¬è¦å­¦ä¹ çš„å‚æ•°ï¼                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. ç»ˆç‚¹ï¼šéªŒè¯æ¢¯åº¦æ˜¯å¦åˆ°è¾¾ z0                                  â”‚
â”‚    if GLOBAL_Z0_ANCHOR.grad is not None:                     â”‚
â”‚        âœ… æ¢¯åº¦æˆåŠŸåä¼ ï¼                                      â”‚
â”‚        grad_mean = z0.grad.abs().mean()                      â”‚
â”‚    else:                                                      â”‚
â”‚        âŒ æ¢¯åº¦æ–­è£‚ï¼Œæ— æ³•å­¦ä¹                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ éªŒè¯çš„æ ¸å¿ƒé—®é¢˜

### é—®é¢˜ï¼šæ¢¯åº¦èƒ½å¦ä» Loss åä¼ åˆ° z0ï¼ˆåˆå§‹å™ªå£°ï¼‰ï¼Ÿ

**ç­”æ¡ˆï¼šèƒ½ï¼** âœ…

### ä¸ºä»€ä¹ˆéœ€è¦éªŒè¯ï¼Ÿ

åœ¨åŸå§‹çš„ diffusion é‡‡æ ·æµç¨‹ä¸­ï¼š
- âŒ åˆå§‹å™ªå£° `z0` é€šå¸¸æ˜¯ `torch.randn_like(...)` éšæœºç”Ÿæˆçš„
- âŒ æ²¡æœ‰ `requires_grad=True`ï¼Œæ— æ³•è®¡ç®—æ¢¯åº¦
- âŒ æ¯æ­¥æ³¨å…¥çš„å™ªå£°æ˜¯ `torch.randn_like(...)`ï¼Œç‹¬ç«‹éšæœºï¼Œæ— æ³•å›ä¼ æ¢¯åº¦

**æˆ‘ä»¬çš„ä¿®æ”¹ï¼š**
- âœ… å°† `z0` è®¾ç½®ä¸º `requires_grad_(True)`
- âœ… å°† `z0` ä¿å­˜åˆ° `GLOBAL_Z0_ANCHOR` ä¾›å¤–éƒ¨è®¿é—®
- âœ… ï¼ˆå¯é€‰ï¼‰æ¯æ­¥å™ªå£°ä» `z0` æ´¾ç”Ÿï¼Œä¿æŒæ¢¯åº¦è¿æ¥

## ğŸ“ å…³é”®ä»£ç ä½ç½®

### 1. åˆ›å»ºå¯å­¦ä¹ çš„ z0ï¼ˆres_sampler.py ç¬¬ 218-226 è¡Œï¼‰

```python
# åˆå§‹åŒ– z0 ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒ
z0 = torch.randn_like(noisy_input_B_StateShape)
z0.requires_grad_(True)  # ğŸ”‘ å…³é”®ï¼šå…è®¸æ¢¯åº¦è®¡ç®—
input_xT_B_StateShape = sigma_max_0 * z0  # x_T = sigma_max * z0

# æš´éœ²ç»™å¤–å±‚ï¼Œä¾¿äºè¯»å–æ¢¯åº¦ / ç”¨ optimizer æ›´æ–°
import sys
current_module = sys.modules[__name__]
current_module.GLOBAL_Z0_ANCHOR = z0  # ğŸ”‘ å…³é”®ï¼šå…¨å±€å˜é‡
```

### 2. æµ‹è¯•è„šæœ¬ä¸­çš„éªŒè¯ï¼ˆtest_gradient_flow.py ç¬¬ 128-165 è¡Œï¼‰

```python
# è®¡ç®— loss
loss = F.mse_loss(output, target)  # output ä¾èµ–äº z0

# åå‘ä¼ æ’­
(-loss).backward()  # æ¢¯åº¦ä» loss â†’ output â†’ ... â†’ z0

# æ£€æŸ¥æ¢¯åº¦
if GLOBAL_Z0_ANCHOR.grad is not None:
    âœ… æ¢¯åº¦æˆåŠŸåä¼ ï¼
    grad_mean = GLOBAL_Z0_ANCHOR.grad.abs().mean()
```

## ğŸ”¬ ä¸¤ç§æ¨¡å¼çš„åŒºåˆ«

### æ¨¡å¼ 1ï¼šé»˜è®¤æ¨¡å¼ï¼ˆå…³é—­éšæœºå™ªå£°æ³¨å…¥ï¼‰
```
æ¢¯åº¦è·¯å¾„ï¼š
loss â†’ output â†’ denoiser â†’ ... â†’ x_T = sigma_max * z0 â†’ z0
                                                          â†‘
                                                      æ¢¯åº¦ç›´æ¥åˆ°è¾¾
```

### æ¨¡å¼ 2ï¼šLearnable Step Noiseï¼ˆä» z0 æ´¾ç”Ÿæ¯æ­¥å™ªå£°ï¼‰
```
æ¢¯åº¦è·¯å¾„ï¼š
loss â†’ output â†’ denoiser â†’ ... â†’ step_noise[i] (ä» z0 æ´¾ç”Ÿ) â†’ z0
                                                          â†‘
                                                      æ¢¯åº¦é€šè¿‡å¯å¾®åˆ†å˜æ¢ä¼ é€’
```

**å…³é”®åŒºåˆ«ï¼š**
- æ¨¡å¼ 1ï¼šæ¯æ­¥**ä¸æ³¨å…¥**é¢å¤–å™ªå£°ï¼ˆ`s_noise=0` æˆ– `learn_noise=True` æ—¶è·³è¿‡ï¼‰
- æ¨¡å¼ 2ï¼šæ¯æ­¥**æ³¨å…¥**ä» `z0` æ´¾ç”Ÿçš„å™ªå£°ï¼ˆä¿æŒæ¢¯åº¦è¿æ¥ï¼‰

## âœ… æµ‹è¯•ç»“æœéªŒè¯äº†ä»€ä¹ˆï¼Ÿ

1. **æ¢¯åº¦è·¯å¾„å®Œæ•´æ€§**ï¼šä» `loss` åˆ° `z0` çš„æ•´ä¸ªè·¯å¾„æ²¡æœ‰æ–­è£‚
2. **z0 å¯å­¦ä¹ æ€§**ï¼š`z0` çš„ `grad` ä¸ä¸º `None`ï¼Œå¯ä»¥è¢«ä¼˜åŒ–å™¨æ›´æ–°
3. **ä¼˜åŒ–å™¨å·¥ä½œæ­£å¸¸**ï¼š`opt.step()` æˆåŠŸæ›´æ–°äº† `z0` çš„å€¼

## ğŸ“ å®é™…åº”ç”¨åœºæ™¯

åœ¨å®é™…çš„ inference ä¸­ï¼ˆ`inference.py`ï¼‰ï¼š

```python
# 1. ç”Ÿæˆå¸¦æ¢¯åº¦çš„è¾“å‡º
output_video = inference_pipeline._generate_img2world_impl(...)

# 2. ç”Ÿæˆ baselineï¼ˆä¸å¸¦æ¢¯åº¦ï¼‰
baseline_out = inference_pipeline.generate_img2world(...)

# 3. è®¡ç®— lossï¼ˆoutput_video å’Œ baseline_out çš„å·®å¼‚ï¼‰
loss = F.mse_loss(output_video, baseline_out)

# 4. åå‘ä¼ æ’­ï¼ˆæœ€å¤§åŒ– lossï¼‰
(-loss).backward()

# 5. æ›´æ–° z0ï¼ˆè®© loss è¶Šæ¥è¶Šå¤§ï¼‰
opt = torch.optim.Adam([_rs.GLOBAL_Z0_ANCHOR], lr=noise_lr)
opt.step()
```

**ç›®æ ‡ï¼š** é€šè¿‡è°ƒæ•´ `z0`ï¼Œè®©ç”Ÿæˆçš„ `output_video` ä¸ `baseline_out` çš„å·®å¼‚è¶Šæ¥è¶Šå¤§ï¼ˆæœ€å¤§åŒ– lossï¼‰ã€‚

## ğŸ“ æ€»ç»“

**éªŒè¯å†…å®¹ï¼š**
- âœ… æ¢¯åº¦ä» `loss` åä¼ åˆ° `output`
- âœ… æ¢¯åº¦ä» `output` åä¼ åˆ°é‡‡æ ·è¿‡ç¨‹çš„æ¯ä¸€æ­¥
- âœ… æ¢¯åº¦æœ€ç»ˆåˆ°è¾¾ `z0`ï¼ˆåˆå§‹å™ªå£°ï¼‰
- âœ… `z0` å¯ä»¥è¢«ä¼˜åŒ–å™¨æ›´æ–°

**éªŒè¯çš„ noiseï¼š**
- âœ… **åˆå§‹ noiseï¼ˆz0ï¼‰**ï¼šè¿™æ˜¯æˆ‘ä»¬è¦å­¦ä¹ çš„å‚æ•°
- âœ… **æ¯æ­¥ noise**ï¼ˆå¦‚æœå¯ç”¨ `learnable_step_noise`ï¼‰ï¼šä» `z0` æ´¾ç”Ÿï¼Œæ¢¯åº¦å¯ä»¥ä¼ é€’å› `z0`


